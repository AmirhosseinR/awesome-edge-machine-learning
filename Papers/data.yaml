# PAPERS
#
# [Template]
#
# -
#   name:
#   description:
---

- name: Applications
  description: >
    There is a countless number of possible edge machine learning applications. Here, we collect papers that describe specific solutions.

-
  name: Federated Learning
  description: >
    Federated Learning enables mobile phones to collaboratively learn a shared prediction model while keeping all the training data on device, decoupling the ability to do machine learning from the need to store the data in the cloud.<sup><a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" target="_blank">Google AI blog: Federated Learning</a></sup>

-
  name: Quantization
  description: >
    Quantization is the process of reducing a precision (from 32 bit floating point into lower bit depth representations) of weights and/or activations in a neural network. The advantages of this method are reduced model size and faster model inference on hardware that support arithmetic operations in lower precision.

-
  name: Pruning
  description: >
    Pruning is a common method to derive a compact network â€“ after training, some structural portion of the parameters is removed, along with its associated computations.<sup><a href="http://jankautz.com/publications/Importance4NNPruning_CVPR19.pdf" target="_blank">Importance Estimation for Neural Network Pruning</a></sup>

-
  name: AutoML
  description: >
    Automated machine learning (AutoML) is the process of automating the end-to-end process of applying machine learning to real-world problems.<sup><a href="https://en.wikipedia.org/wiki/Automated_machine_learning" targe="_blank">Wikipedia</a></sup> AutoML is for example used to design new efficient neural architectures with a constraint on a computational budget (defined either as a number of FLOPS or as an inference time measured on real device) or a size of the architecture.

-
  name: Efficient Architectures
  description: >
    Efficient architectures represent neural networks with small memory footprint and fast inference time when measured on edge devices.

...
